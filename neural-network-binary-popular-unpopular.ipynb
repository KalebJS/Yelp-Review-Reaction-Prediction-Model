{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import config as c\n",
    "\n",
    "df_popular = pd.read_pickle(c.PATHS.OBJECTS_FOLDER / \"transformed_data_popular.pickle\")\n",
    "with open(c.PATHS.OBJECTS_FOLDER / \"embeddings_popular.pkl\", \"rb\") as f:\n",
    "    embeddings_popular = pickle.load(f)\n",
    "\n",
    "df_unpopular = pd.read_pickle(c.PATHS.OBJECTS_FOLDER / \"transformed_data_unpopular.pickle\")\n",
    "with open(c.PATHS.OBJECTS_FOLDER / \"embeddings_unpopular.pickle\", \"rb\") as f:\n",
    "    embeddings_unpopular = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with \"city_*\" in the name\n",
    "df_popular = df_popular.drop(columns=[col for col in df_popular.columns if \"city_\" in col])\n",
    "df_unpopular = df_unpopular.drop(columns=[col for col in df_unpopular.columns if \"city_\" in col or \"categor\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223152, 10), (223152, 768), (203012, 10), (203012, 768))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_popular.shape, embeddings_popular.shape, df_unpopular.shape, embeddings_unpopular.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the embeddings (numpy array) in the dataframe\n",
    "df_popular[\"embeddings\"] = embeddings_popular.tolist()\n",
    "df_unpopular[\"embeddings\"] = embeddings_unpopular.tolist()\n",
    "df_popular[\"is_popular\"] = 1\n",
    "df_unpopular[\"is_popular\"] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.concat([df_popular, df_unpopular])\n",
    "X = df.drop(columns=[\"is_popular\"])\n",
    "y = df[\"is_popular\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build keras neural network model to predict binary popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embeddings = X_train[\"embeddings\"].values.tolist()\n",
    "X_test_embeddings = X_test[\"embeddings\"].values.tolist()\n",
    "\n",
    "# convert the list of embeddings to a numpy array\n",
    "import numpy as np\n",
    "\n",
    "X_train_embeddings = np.array(X_train_embeddings, dtype=np.float32)\n",
    "X_test_embeddings = np.array(X_test_embeddings, dtype=np.float32)\n",
    "\n",
    "X_train = X_train.drop(columns=[\"embeddings\"])\n",
    "X_test = X_test.drop(columns=[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all columns are numeric\n",
    "X_train = X_train.apply(pd.to_numeric)\n",
    "X_test = X_test.apply(pd.to_numeric)\n",
    "\n",
    "# fill missing values with 0\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 23:05:58.251530: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10655/10655 [==============================] - 16s 664us/step - loss: nan - accuracy: 0.9031 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 2/10\n",
      "10655/10655 [==============================] - 7s 648us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 3/10\n",
      "10655/10655 [==============================] - 7s 624us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 4/10\n",
      "10655/10655 [==============================] - 7s 648us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 5/10\n",
      "10655/10655 [==============================] - 7s 661us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 6/10\n",
      "10655/10655 [==============================] - 7s 660us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 7/10\n",
      "10655/10655 [==============================] - 7s 641us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 8/10\n",
      "10655/10655 [==============================] - 7s 672us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 9/10\n",
      "10655/10655 [==============================] - 7s 679us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n",
      "Epoch 10/10\n",
      "10655/10655 [==============================] - 7s 659us/step - loss: nan - accuracy: 0.4769 - val_loss: nan - val_accuracy: 0.4741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5d7d51970>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Define input layers for text data and embeddings\n",
    "input_text = Input(shape=(X_train.shape[1],))\n",
    "input_embed = Input(shape=(len(X_train_embeddings[0]),))\n",
    "\n",
    "# Define dense layers for text data and embeddings\n",
    "dense_text = Dense(64, activation='relu')(input_text)\n",
    "dense_embed = Dense(64, activation='relu')(input_embed)\n",
    "\n",
    "# Concatenate the dense layers\n",
    "concat = concatenate([dense_text, dense_embed])\n",
    "\n",
    "# Define output layer\n",
    "output = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[input_text, input_embed], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit([X_train, X_train_embeddings], y_train, epochs=10, batch_size=32, validation_data=([X_test, X_test_embeddings], y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
